{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# QUE.1:- Basic text preprocessing (tokenization, lowercasing, removing punctuation).\n",
        "\n",
        "#Basic text preprocessing is an essential step in natural language processing (NLP) tasks\n",
        "# 1.Tokenization: Splitting text into smaller parts, such as words, sentences, or subwords.\n",
        "#Example:Input: \"Hello, World!\" ,Output: [\"Hello\", \",\", \"World\", \"!\"] (Word tokenization)\n",
        "\n",
        "# 2.Lowercasing: Converting all text to lowercase to ensure consistency.\n",
        "#Example:Input: \"Hello World!\" , Output: \"hello world!\"\n",
        "\n",
        "#3. Removing Punctuation: Eliminating punctuation marks to focus on the core content of the text.\n",
        "#Example:Input: \"Hello, World!\",Output: \"Hello World\"\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK data (only need to run once)\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Removing punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenizing\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Example usage\n",
        "text = \"Toutche electric bicycles are eco-friendly and efficient \"\n",
        "preprocessed_text = preprocess_text(text)\n",
        "print(preprocessed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAXoeGft6SBc",
        "outputId": "830bc77b-7909-4164-880a-a2947dcf69c6"
      },
      "id": "pAXoeGft6SBc",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['toutche', 'electric', 'bicycles', 'are', 'ecofriendly', 'and', 'efficient']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pTc2KnQjcVL0"
      },
      "id": "pTc2KnQjcVL0"
    },
    {
      "cell_type": "code",
      "source": [
        "#A RegEx, or Regular Expression, is a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern\n",
        "import re\n",
        "text = \"My email address is john.doe@example.com\"\n",
        "\n",
        "# Search for an email address\n",
        "match = re.search(r\"\\w+@\\w+\\.\\w+\", text)\n",
        "\n",
        "if match:\n",
        "    print(\"Email found:\", match.group())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svO9Ayro8uuN",
        "outputId": "3a866e8f-bd1c-473e-e268-4676c4f3b26c"
      },
      "id": "svO9Ayro8uuN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email found: doe@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUE2:-  function that can identify keywords related to Toutche's products in agiven text\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "# Define a list of keywords related to Toutche's products\n",
        "keywords = [\n",
        "    \"e-bike\", \"ebike\", \"electric bike\", \"electric bicycle\",\n",
        "    \"cycle\", \"bicycle\", \"pedal assist\", \"battery\", \"motor\",\n",
        "    \"charging\", \"range\", \"Toutche\", \"Heileo\", \"speed\", \"brakes\", \"tyres\"\n",
        "]\n",
        "\n",
        "def identify_keywords(text, keywords):\n",
        "    # Convert text to lowercase for case-insensitive matching\n",
        "    text = text.lower()\n",
        "\n",
        "    # Create a set to store found keywords\n",
        "    found_keywords = set()\n",
        "\n",
        "    # Check each keyword in the text\n",
        "    for keyword in keywords:\n",
        "        # Use regex to find whole words matching the keywords\n",
        "        if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text):\n",
        "            found_keywords.add(keyword)\n",
        "\n",
        "    return list(found_keywords)\n",
        "\n",
        "# Example usage\n",
        "text = \"The new Toutche Heileo e-bike comes with an improved battery and pedal assist.\"\n",
        "detected_keywords = identify_keywords(text, keywords)\n",
        "print(detected_keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa8DAsDDZ3lP",
        "outputId": "d36f75eb-7ccb-4e52-a2fb-2c6395a02be0"
      },
      "id": "Fa8DAsDDZ3lP",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['e-bike', 'battery', 'Heileo', 'Toutche', 'pedal assist']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "# Sample training data\n",
        "X = [\"How much the bicyles cost in mountain range series?\",\" Is it availabale offline on stores? \",\"Do you offer test rides?\"]\n",
        "y = [\"pricing\", \"product_info\", \"services\"]\n",
        "# Create a pipeline\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "# Predict intent\n",
        "new_query = \"i can buy online or offline?\"\n",
        "print(model.predict([new_query]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT8aoGdIa_61",
        "outputId": "57a90d9b-2340-453d-834b-eb442f5612eb"
      },
      "id": "FT8aoGdIa_61",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['product_info']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#COMMENTS EXPLAINING YOUR CODE AND THOUGHT PROCESS\n",
        "**Thought Process Behind the Code:**\n",
        "\n",
        "1.**Keyword List**\n",
        "\n",
        "\n",
        "The list of keywords (keywords) contains\n",
        "terms that are specifically related to Toutche's products and the e-bike industry, such as \"e-bike,\" \"battery,\" \"pedal assist,\" and product names like \"Heileo.\" These keywords are predefined based on knowledge of the product.\n",
        "\n",
        "The list can be expanded with new terms or tailored to focus on specific product features.\n",
        "\n",
        "2.**Lowercasing:**\n",
        "\n",
        "Why lowercasing?\n",
        "-- Text data can have mixed cases, and we want to ensure that the matching is case-insensitive. Lowercasing both the input text and keywords allows us to find matches regardless of case.\n",
        "\n",
        "**3.Regex for Matching:**\n",
        "\n",
        "The regular expression r'\\b' + re.escape\n",
        "(keyword.lower()) + r'\\b' is used to find exact keyword matches,\n",
        " where:\n",
        "--\\b ensures the keyword is a whole word. This prevents false positives, such as finding \"cycle\" inside the word \"recycle.\"\n",
        "\n",
        "--re.escape() is used to handle any special characters in the keyword properly (though our current keyword list doesn't have special characters).\n",
        "This approach ensures robust and accurate keyword matching.\n",
        "\n",
        "**4.Set for Storing Found Keywords:**\n",
        "\n",
        "We use a set (found_keywords) to store the detected keywords. Why a set? Sets automatically handle duplicates, so if a keyword appears multiple times in the text, itâ€™s added only once.\n",
        "\n",
        "After finding all keywords, we convert the set back to a list to maintain a simple structure for output.\n",
        "\n",
        "**5.Returning the List:**\n",
        "\n",
        "The function returns a list of found keywords for easier handling by the user. Lists are a common and easy-to-use data structure for further processing or displaying results."
      ],
      "metadata": {
        "id": "bO_o8borcYNt"
      },
      "id": "bO_o8borcYNt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}